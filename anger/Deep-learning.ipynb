{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, Bidirectional, GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import polars as pl\n",
    "\n",
    "def load_and_preprocess_data(train_file, dev_file, test_file, max_features, max_words):\n",
    "    # Load the data\n",
    "    data_train = pl.read_csv(train_file)\n",
    "    data_dev = pl.read_csv(dev_file)\n",
    "    data_test = pl.read_csv(test_file)\n",
    "\n",
    "    # Ensure the Tweet column is in string format\n",
    "    data_train = data_train.with_column(pl.col(\"Tweet\").cast(pl.Utf8))\n",
    "    data_dev = data_dev.with_column(pl.col(\"Tweet\").cast(pl.Utf8))\n",
    "    data_test = data_test.with_column(pl.col(\"Tweet\").cast(pl.Utf8))\n",
    "\n",
    "    # Convert target variables to categorical\n",
    "    y_train = to_categorical(data_train['Intensity_Class'].to_numpy())\n",
    "    y_val = to_categorical(data_dev['Intensity_Class'].to_numpy())\n",
    "    y_test = to_categorical(data_test['Intensity_Class'].to_numpy())\n",
    "\n",
    "    # Prepare the training, validation, and test data\n",
    "    X_train = data_train['Tweet'].to_list()\n",
    "    X_val = data_dev['Tweet'].to_list()\n",
    "    X_test = data_test['Tweet'].to_list()\n",
    "\n",
    "    # Tokenize the text data\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    # Pad sequences\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=max_words)\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=max_words)\n",
    "    X_test_pad = pad_sequences(X_test_seq, maxlen=max_words)\n",
    "\n",
    "    return X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test\n",
    "\n",
    "def build_and_compile_model(max_features, max_words, num_classes):\n",
    "    # Define the Bidirectional GRU model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 100, input_length=max_words))\n",
    "    model.add(SpatialDropout1D(0.25))\n",
    "    model.add(Bidirectional(GRU(64, dropout=0.4, return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(32, dropout=0.5, return_sequences=False)))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model with a smaller learning rate\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
