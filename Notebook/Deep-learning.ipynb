{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM, Bidirectional, GRU, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_and_preprocess_data(train_file, dev_file, test_file, max_features, max_words):\n",
    "    # Load the data\n",
    "    data_train = pl.read_csv(train_file)\n",
    "    data_dev = pl.read_csv(dev_file)\n",
    "    data_test = pl.read_csv(test_file)\n",
    "\n",
    "    # Ensure the Tweet column is in string format\n",
    "    data_train = data_train.with_column(pl.col(\"Tweet\").cast(pl.Utf8))\n",
    "    data_dev = data_dev.with_column(pl.col(\"Tweet\").cast(pl.Utf8))\n",
    "    data_test = data_test.with_column(pl.col(\"Tweet\").cast(pl.Utf8))\n",
    "\n",
    "    # Convert target variables to categorical\n",
    "    y_train = to_categorical(data_train['Intensity_Class'].to_numpy())\n",
    "    y_val = to_categorical(data_dev['Intensity_Class'].to_numpy())\n",
    "    y_test = to_categorical(data_test['Intensity_Class'].to_numpy())\n",
    "\n",
    "    # Prepare the training, validation, and test data\n",
    "    X_train = data_train['Tweet'].to_list()\n",
    "    X_val = data_dev['Tweet'].to_list()\n",
    "    X_test = data_test['Tweet'].to_list()\n",
    "\n",
    "    # Tokenize the text data\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    # Pad sequences\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=max_words)\n",
    "    X_val_pad = pad_sequences(X_val_seq, maxlen=max_words)\n",
    "    X_test_pad = pad_sequences(X_test_seq, maxlen=max_words)\n",
    "\n",
    "    return X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test\n",
    "\n",
    "def create_wordcloud(text, title=None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='black',\n",
    "        max_words=200,\n",
    "        max_font_size=40,\n",
    "        scale=3,\n",
    "        random_state=1\n",
    "    ).generate(str(text))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(15, 15))\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "def build_and_compile_cnn_model(max_features, max_words, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 100, input_length=max_words))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_and_compile_lstm_model(max_features, max_words, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 100, input_length=max_words))\n",
    "    model.add(LSTM(64, dropout=0.4, return_sequences=True))\n",
    "    model.add(LSTM(32, dropout=0.5, return_sequences=False))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_and_compile_bgru_model(max_features, max_words, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 100, input_length=max_words))\n",
    "    model.add(SpatialDropout1D(0.25))\n",
    "    model.add(Bidirectional(GRU(64, dropout=0.4, return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(32, dropout=0.5, return_sequences=False)))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def main(train_file, dev_file, test_file, model_type='bgru'):\n",
    "    # Define parameters\n",
    "    max_features = 5000\n",
    "    max_words = 100\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    num_classes = 4\n",
    "\n",
    "    # Load and preprocess the data\n",
    "    X_train_pad, y_train, X_val_pad, y_val, X_test_pad, y_test = load_and_preprocess_data(train_file, dev_file, test_file, max_features, max_words)\n",
    "\n",
    "    # Build and compile the model\n",
    "    if model_type == 'cnn':\n",
    "        model = build_and_compile_cnn_model(max_features, max_words, num_classes)\n",
    "    elif model_type == 'lstm':\n",
    "        model = build_and_compile_lstm_model(max_features, max_words, num_classes)\n",
    "    elif model_type == 'bgru':\n",
    "        model = build_and_compile_bgru_model(max_features, max_words, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model_type. Choose from 'cnn', 'lstm', or 'bgru'.\")\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Define early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val), epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "    print(f'Test Loss: {loss}')\n",
    "    print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_file = 'path/to/train.csv'\n",
    "    dev_file = 'path/to/dev.csv'\n",
    "    test_file = 'path/to/test.csv'\n",
    "    main(train_file, dev_file, test_file, model_type='bgru')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
